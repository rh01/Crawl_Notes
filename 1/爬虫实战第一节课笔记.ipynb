{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 什么是网络爬虫\n",
    "1. 定义\n",
    "    1. 网络爬虫（又称为网页蜘蛛，网络机器人，在FOAF社区之间更经常地称为网页追随者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。\n",
    "    2. 由于专门用于信息检索的“机器人程序”像蜘蛛一样在网络之间爬来爬去，因此，搜索引擎的“机器人”程序就被称为“蜘蛛”程序\n",
    "2. 历史\n",
    "    1. 1990年，蒙特利尔大学学生Alan Emtage发明的Archie，用于搜索分散的FTP主机上的资源。\n",
    "    2. 1993年，内华达大学受启发开发了类似工具，但是开始支持网页搜索。\n",
    "    3. Martin Koster于1993年10月创建了ALIWEB，它是Archie的HTTP版本。ALIWEB不使用“机器人”程序，而是靠网站主动提交信息来建立自己的链接索引，类似于现在我们熟知的Yahoo。\n",
    "    4. Yahoo, Google, Baidu, Bing...\n",
    "\n",
    "3. 使用[Python](https://www.python.org/)写爬虫的好处\n",
    "    1. 上手容易！！！\n",
    "    2. 免费开源，使用不受限制。\n",
    "    3. 解释执行，跨平台不受限制。\n",
    "    4. 面向对象\n",
    "    5. 框架和库支持丰富，有大量的历史积累。\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python开发环境搭建和简介\n",
    "1. Python简介\n",
    "    1. 官网：https://www.python.org/\n",
    "    2. 作者：Guido van Rossum\n",
    "    3. 名字来源：Monty Python's Flying Circus（和蟒蛇无关啊！）\n",
    "    4. 作者为什么发明Python：平衡C和Shell\n",
    "    5. 版本选择：2.7和3.5，更低版本不推荐使用。2.x和3.x的区别暂时不用关心。\n",
    "2. Python环境搭建\n",
    "    1. Windows可去官网下载安装包：2.7.12或3.5.2\n",
    "    2. Mac\n",
    "    3. 系统自带\n",
    "    4. 通过homebrew和pyenv安装并维护多个Python版本，参考链接。\n",
    "    5. Linux系统自带，或参考上面链接使用pyenv安装并维护多个Python版本\n",
    "    6. 使用pip安装第三方包，命令为pip install package（注：Mac下需要打开sudo，参考链接。）\n",
    "    7. 新版本Mac系统可能因为SIP，需要在命令行后增加--user参数\n",
    "    8. 遇到GFW可以使用国内源（推荐豆瓣），命令行为pip install package -i --trusted-host http://pypi.douban.com/simple/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP简介\n",
    "1. HTTP = HyperText Transfer Protocol\n",
    "2. URI = Uniform Resource Identifier\n",
    "3. URL = Uniform Resource Locator\n",
    "4. URI和URL的区别：URI强调的是资源，而URL强调的是资源的位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常用请求类型\n",
    "1. OPTIONS: 返回服务器针对特定资源所支持的http请求方法。\n",
    "2. HEAD: 向服务器索要与get请求相一致的响应，只不过响应体将不会被返回。\n",
    "3. GET: 向特定资源发出请求 \n",
    "4. PUT: 向指定资源位置上传其最新内容\n",
    "5. POST: 向指定资源提交数据进行处理请求\n",
    "6. DELETE: 请求服务器删除指定URI所标识的资源\n",
    "7. PATCH: 用来将局部修改应用于某一资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML (Hypertext Markup Language)\n",
    "1. 推荐教程：[HTML](http://www.runoob.co/html/html-tutorial.html)\n",
    "2. HTML不是编程语言，而是一种标记语言。即HTML使用标记标签来描述网页。\n",
    "3. 标签和元素\n",
    "4. DOM文档模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "<标签 属性=\"属性的值\"></标签>\n",
    "\n",
    "比如：\n",
    "<a href=\"www.baidu.com\"><a>\n",
    "<p></p>\n",
    "<h1></h1>\n",
    "....\n",
    "\n",
    "DOM文档模型：\n",
    "文本<body>\n",
    "    - 段落1 <p>...</p>\n",
    "      - 列表 <ul>...</ul>\n",
    "      - 图片 <img src=\"\"> </img>\n",
    "      - 文本\n",
    "    -段落2\n",
    "      - 列表\n",
    "      - ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML (eXtensible Markup Language)\n",
    "1. 推荐教程：[XML](http://www.runoob.com/xml/xml-tutorial.html)\n",
    "2. 树结构\n",
    "![tree](http://p1.bqimg.com/567571/f2024edea71ebef5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "ROOT\n",
    "    - E1\n",
    "      - G1\n",
    "      - G1 -> 属性/值\n",
    "    - E2\n",
    "    - E3\n",
    "    \n",
    "<node attr=value>...</node>\n",
    "[ROOT][E1][G1].text\n",
    "[ROOT][E2][G1].text\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Json (JavaScript Object Notation)\n",
    "1. 推荐教程：[Json](http://www.runoob.com/json/json-tutorial.html)\n",
    "2. 语法类似XML，但是更小、更快、更容易解析。对JavaScript特别友好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MySQL\n",
    "1. Windows:\n",
    "    1. [下载](http://dev.mysql.com/downloads/mysql/)免费社区版mysql server。\n",
    "    2. 客户端操作可以使用[MySQLWorkbench](http://www.mysql.com/products/workbench/)。\n",
    "2. Linux（以debian为例）\n",
    "    \n",
    "    1.apt-get install mysql-server mysql-client    \n",
    "    2.登陆mysql: mysql -p hostname -u username -p，然后使用use dbname指定需要操作的数据库    \n",
    "    3.安装[phpmyadmin](https://www.phpmyadmin.net/)方便在浏览器操作数据库\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MySQL常用命令\n",
    "1. show databases: 显示当前服务器上的数据库\n",
    "2. create database dbname: 创建一个新数据库\n",
    "3. use dbname: 使用指定的数据库\n",
    "4. show tables: 显示当前数据库的所有表\n",
    "5. desc tbname: 显示表结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite\n",
    "1. Windows直接去[下载](http://www.sqlite.org/download.html)可执行文件即可使用，Linux下apt-get install sqlite3即可完成安装。\n",
    "2. 相比mysql更加轻便好用。\n",
    "3. 大数据情况下效率变差，适合单机小程序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 爬虫框架介绍\n",
    "### 工作流程\n",
    "1. 将种子URL放入队列\n",
    "2. 从队列中获取URL，抓取内容。\n",
    "3. 解析抓取内容，将需要进一步抓取的URL放入工作队列，存储解析后的内容\n",
    "\n",
    "## 抓取策略\n",
    "1. 深度优先\n",
    "2. 广度优先\n",
    "3. PageRank\n",
    "4. 大站优先策略\n",
    "\n",
    "## 如何去重\n",
    "1. Hash表\n",
    "2. bloom过滤器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "news.sina.com.cn\n",
    "\n",
    "1.sina.com.cn\n",
    "2.sina.com.cn\n",
    "\n",
    "news.sina.com.cn\n",
    "    - 专题1\n",
    "      - news11\n",
    "      - news12\n",
    "      - news13\n",
    "    - 专题2\n",
    "      - news21\n",
    "      - news22\n",
    "      - news23\n",
    "DFS（深度）:\n",
    "working\n",
    "专题1\n",
    "11\n",
    "12\n",
    "13\n",
    "\n",
    "working\n",
    "专题2\n",
    "21\n",
    "22\n",
    "23\n",
    "\n",
    "BFS（广度）：\n",
    "working\n",
    "专题1\n",
    "专题2\n",
    "\n",
    "11\n",
    "12\n",
    "13\n",
    "\n",
    "21\n",
    "22\n",
    "23\n",
    "\n",
    "PageRank:\n",
    "给网页打值\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robots规范与原则\n",
    "### Robots规范\n",
    "1. Robots协议（也称为爬虫协议、机器人协议等）的全称是“网络爬虫排除标准”（Robots Exclusion Protocol），网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取。Robots协议的本质是网站和搜索引擎爬虫的沟通方式，用来指导搜索引擎更好地抓取网站内容，而不是作为搜索引擎之间互相限制和不正当竞争的工具。\n",
    "2. 详情：http://baike.so.com/doc/4854891-5072162.html\n",
    "\n",
    "## 爬虫质量标准\n",
    "1. 分布式\n",
    "2. 可伸缩性\n",
    "3. 性能和有效性\n",
    "4. 质量\n",
    "5. 新鲜性\n",
    "6. 更新\n",
    "7. 可扩展性\n",
    "\n",
    "### 扯得远点\n",
    "1. Map/Reduce背后\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 例子1\n",
    "目标：获取某一个省的邮编区号\n",
    "目标网站： www.ip138.com/post/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新疆 /83/\n",
      "西藏 /85/\n",
      "青海 /81/\n",
      "甘肃 /73/\n",
      "四川 /61/\n",
      "云南 /65/\n",
      "宁夏 /75/\n",
      "内蒙古 /01/\n",
      "黑龙江 /15/\n",
      "吉林 /13/\n",
      "辽宁 /11/\n",
      "河北 /50/\n",
      "北京 /10/\n",
      "天津 /30/\n",
      "陕西 /71/\n",
      "山西 /03/\n",
      "山东 /25/\n",
      "河南 /45/\n",
      "重庆 /40/\n",
      "湖北 /43/\n",
      "安徽 /23/\n",
      "江苏 /21/\n",
      "上海 /20/\n",
      "贵州 /55/\n",
      "广西 /53/\n",
      "湖南 /41/\n",
      "江西 /33/\n",
      "浙江 /31/\n",
      "福建 /35/\n",
      "广东 /51/\n",
      "海南 /57/\n",
      "台湾 /taiwang/\n",
      "澳门 /aomen/\n",
      "香港 /xianggang/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.parsers.expat import ParserCreate\n",
    "\n",
    "class DefaultSaxHandler(object):\n",
    "    def __init__(self, provinces):\n",
    "        self.provinces = provinces\n",
    "\n",
    "    # 处理标签开始\n",
    "    def start_element(self, name, attrs):\n",
    "        if name != 'map':\n",
    "            name = attrs['title']\n",
    "            number = attrs['href']\n",
    "            self.provinces.append((name, number))\n",
    "\n",
    "    # 处理标签结束\n",
    "    def end_element(self, name):\n",
    "        pass\n",
    "\n",
    "    # 文本处理\n",
    "    def char_data(self, text):\n",
    "        pass\n",
    "    \n",
    "def get_province_entry(url):\n",
    "    # 获取文本，并用gb2312解码\n",
    "    content = requests.get(url).content.decode('gb2312')\n",
    "    # 确定要查找字符串的开始结束位置，并用切片获取内容。\n",
    "    start = content.find('<map name=\\\"map_86\\\" id=\\\"map_86\\\">')\n",
    "    end = content.find('</map>')\n",
    "    content = content[start:end + len('</map>')].strip().encode('utf8')\n",
    "    provinces = []\n",
    "    # 生成Sax处理器\n",
    "    handler = DefaultSaxHandler(provinces)\n",
    "    # 初始化分析器\n",
    "    parser = ParserCreate()\n",
    "    parser.StartElementHandler = handler.start_element\n",
    "    parser.EndElementHandler = handler.end_element\n",
    "    parser.CharacterDataHandler = handler.char_data\n",
    "    # 解析数据\n",
    "    parser.Parse(content)\n",
    "    # 结果字典为每一页的入口代码\n",
    "    return provinces\n",
    "\n",
    "provinces = get_province_entry('http://www.ip138.com/post')\n",
    "for i in provinces:\n",
    "    print(i[0],i[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 例子2\n",
    "抓取股票信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var hq_str_sh600001=\"\";\n",
      "\n",
      "var hq_str_sh600002=\"\";\n",
      "\n",
      "var hq_str_sh600003=\"\";\n",
      "\n",
      "var hq_str_sh600004=\"白云机场,14.480,14.480,14.330,14.510,14.320,14.320,14.330,4926788,70978480.000,35700,14.320,30700,14.310,60300,14.300,52400,14.290,20400,14.280,4200,14.330,20300,14.340,14100,14.350,2500,14.360,5702,14.370,2017-02-17,15:00:00,00\";\n",
      "\n",
      "var hq_str_sh600005=\"武钢股份,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0,0.000,0,0.000,0,0.000,0,0.000,0,0.000,0,0.000,0,0.000,0,0.000,0,0.000,0,0.000,0,0.000,2017-02-17,09:14:18,00\";\n",
      "\n",
      "var hq_str_sh600006=\"东风汽车,7.000,7.020,7.160,7.350,6.940,7.150,7.160,34238293,243779395.000,41100,7.150,160200,7.140,81600,7.130,289391,7.120,81200,7.110,150971,7.160,235900,7.170,235000,7.180,228890,7.190,403400,7.200,2017-02-17,15:00:00,00\";\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import threading\n",
    "\n",
    "def display_info(code):\n",
    "    url = 'http://hq.sinajs.cn/list=' + code\n",
    "    response = requests.get(url).text\n",
    "    print(response)\n",
    "    \n",
    "def single_thread(codes):\n",
    "    for code in codes:\n",
    "        code = code.strip()\n",
    "        display_info(code)\n",
    "\n",
    "def multi_thread(tasks):\n",
    "    # 用列表推导生成线程，注意codes后面的‘，’!\n",
    "    threads = [threading.Thread(target = single_thread, args = (codes,)) for codes in tasks]\n",
    "    # 启动线程\n",
    "    for t in threads:\n",
    "        t.start()\n",
    "    # 等待线程结束\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "# 注意main函数的形式\n",
    "if __name__ == '__main__':\n",
    "    codes = ['sh600001', 'sh600002', 'sh600003', 'sh600004', 'sh600005', 'sh600006']\n",
    "    # 计算每个线程要做多少工作\n",
    "    thread_len = int(len(codes) / 4)\n",
    "    t1 = codes[0: thread_len]\n",
    "    t2 = codes[thread_len: thread_len * 2]\n",
    "    t3 = codes[thread_len * 2: thread_len * 3]\n",
    "    t4 = codes[thread_len * 3:]\n",
    "\n",
    "    # 多线程启动\n",
    "    multi_thread([t1, t2, t3, t4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
